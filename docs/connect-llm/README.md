# Backup & Restore Guide

This folder provides documentation and instructions for adding various LLMs into RAM.

## Contents

- [azure foundry.md](./azure-openai.md): Steps to integrate the azure openai foundry resource with RAM
- [ollama.md](./ollama.md): Steps to integrate an ollama deployment with RAM
- [amazon bedrock.md](./bedrock.md): Steps to integrate the amazon bedrock resource with RAM
- [openai.md](./openai.md): Steps to connect an openai endpoint with RAM

## Purpose

These documents are intended to help users:

- Connect 4 types of LLMs to their RAM deployment
- Configure settings to allow for connectivity with each LLM
